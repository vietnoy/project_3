# Smart Contract Security Assistant - Complete Guide

**A comprehensive guide from foundational concepts to advanced implementation**

---

## Table of Contents

1. [Quick Start](#quick-start)
2. [Project Overview](#project-overview)
3. [Foundational Concepts](#foundational-concepts)
4. [Architecture Deep Dive](#architecture-deep-dive)
5. [Code Walkthrough](#code-walkthrough)
6. [How It Works: Step by Step](#how-it-works-step-by-step)
7. [Advanced Topics](#advanced-topics)
8. [Presenting to Your Teacher](#presenting-to-your-teacher)

---

## Quick Start

### Setup and Run

1. **Install Ollama** (Free Local LLM)
   - Download from: https://ollama.com/download
   - Run installer
   - Open terminal and run: `ollama pull gemma3:4b`
   - Wait for download (~3.3GB)

2. **Run the Application**
   ```bash
   python src/main.py
   ```

3. **Test It**
   - Select mode `1` (Q&A)
   - Ask: "What is a reentrancy attack?"
   - The bot will answer using your local dataset!

### What This Uses (100% Free)
- **Ollama + gemma3:4b**: Local LLM (runs on your computer, no API costs)
- **HuggingFace Embeddings**: Free sentence transformers (all-MiniLM-L6-v2)
- **ChromaDB**: Free local vector database
- **Your Dataset**: 1000+ smart contract vulnerability findings

**Zero cost. Runs offline.**

---

## Project Overview

### What Does This Project Do?

This is a RAG-powered (Retrieval-Augmented Generation) chatbot that helps with smart contract security in 3 ways:

1. **Q&A** - Answer security questions
   - Example: "What is a reentrancy attack?"
   - Bot retrieves relevant findings from your dataset and generates an answer

2. **Code Analysis** - Identify vulnerabilities in code
   - User pastes Solidity code
   - Bot searches for similar vulnerabilities
   - Returns detailed security analysis with severity levels

3. **Code Fixing** - Automatically fix vulnerable code
   - User pastes vulnerable code
   - Bot retrieves fix recommendations from dataset
   - Returns corrected code with explanations

### Why This Project?

**Your teacher wants to see:**
- Understanding of AI/LLM applications
- Knowledge of RAG vs other approaches (like finetuning)
- Ability to build practical applications
- Understanding of smart contract security (domain knowledge)

---

## Foundational Concepts

### 1. What is RAG (Retrieval-Augmented Generation)?

**Simple Explanation:**
RAG is like giving an AI an open-book exam instead of making it memorize everything.

**How it works:**
```
User Question ‚Üí Search Relevant Documents ‚Üí Feed to LLM ‚Üí Generate Answer
```

**Example:**
```
User: "What is a reentrancy attack?"
  ‚Üì
Step 1: Search your 1000+ vulnerability findings
Step 2: Find top 5 most relevant findings about reentrancy
Step 3: Give those findings + question to the LLM
Step 4: LLM generates answer based on YOUR data
```

**Why RAG?**
- ‚úÖ Cheaper than finetuning ($0.01 vs $100+)
- ‚úÖ Works with small datasets (1000 findings is perfect)
- ‚úÖ Easy to update (just add new findings)
- ‚úÖ More accurate (uses actual data, not memorized patterns)
- ‚úÖ Transparent (you can see which findings were used)

### 2. RAG vs Finetuning

**RAG (What you're using):**
- Retrieves relevant knowledge at query time
- Like: "Here are 5 relevant documents, now answer based on them"
- Cost: ~$0.01-0.05 per query
- Data needed: 100-10,000 documents
- Use case: Knowledge-based Q&A

**Finetuning:**
- Trains the model to memorize patterns
- Like: "Learn to always respond in this style/format"
- Cost: $100-1000+ to train
- Data needed: 10,000-100,000+ examples
- Use case: Changing model behavior/style

**Your project uses RAG because:**
- You have knowledge (vulnerability findings) not behavior change needs
- 1000+ findings is perfect for RAG but too small for finetuning
- LLMs already know how to code - they just need security knowledge
- Much cheaper and faster to implement

### 3. What is an Embedding?

**Simple Explanation:**
Convert text into numbers so computers can understand similarity.

**How it works:**
```
Text: "reentrancy attack"
  ‚Üì
Embedding Model (all-MiniLM-L6-v2)
  ‚Üì
Vector: [0.23, -0.45, 0.78, ..., 0.12]  (384 numbers)
```

**Why vectors?**
- Similar meanings = similar vectors
- "reentrancy attack" is close to "reentrant vulnerability"
- "reentrancy attack" is far from "documentation update"
- Enables semantic search (search by meaning, not just keywords)

**Example:**
```
Query: "prevent recursive calls"
Similar finding: "reentrancy vulnerability allows recursive function calls"
‚Üí Even though words are different, vectors are similar!
```

### 4. What is a Vector Database?

**Simple Explanation:**
A database that stores embeddings and finds similar ones quickly.

**Regular Database:**
```sql
SELECT * FROM vulnerabilities WHERE title = "reentrancy"
```
‚Üí Only finds exact matches

**Vector Database:**
```python
vectorstore.similarity_search("prevent recursive calls")
```
‚Üí Finds semantically similar content even with different words

**How ChromaDB works:**
1. Store embeddings: `[vulnerability_1_vector, vulnerability_2_vector, ...]`
2. When user asks a question, convert it to a vector
3. Find the 5 closest vectors (cosine similarity)
4. Return the original documents

### 5. What is LangChain?

**Simple Explanation:**
A framework that makes building LLM apps easier. Like React for AI apps.

**Without LangChain (manual approach):**
```python
# 200+ lines of code
- Load JSON files manually
- Convert to embeddings manually
- Store in vector DB manually
- Retrieve documents manually
- Format prompt manually
- Call LLM manually
- Parse response manually
```

**With LangChain:**
```python
# ~30 lines of code
from langchain.chains import RetrievalQA

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever()
)
result = qa_chain("What is reentrancy?")
```

**What LangChain provides:**
- **Document Loaders**: Load JSON, PDF, CSV, etc.
- **Text Splitters**: Break long documents into chunks
- **Embeddings**: OpenAI, HuggingFace, Cohere, etc.
- **Vector Stores**: ChromaDB, Pinecone, FAISS, etc.
- **LLM Wrappers**: OpenAI, Claude, Llama, etc.
- **Chains**: Pre-built workflows (RetrievalQA, ConversationalRetrieval, etc.)
- **Memory**: Conversation history management
- **Agents**: LLMs that can use tools

---

## Architecture Deep Dive

### High-Level Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              USER INTERFACE                     ‚îÇ
‚îÇ  Mode 1: Ask Question                           ‚îÇ
‚îÇ  Mode 2: Analyze Code                           ‚îÇ
‚îÇ  Mode 3: Fix Code                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         SmartContractSecurityBot                ‚îÇ
‚îÇ  - self.vectorstore (ChromaDB)                  ‚îÇ
‚îÇ  - self.llm (Ollama gemma3:4b)                  ‚îÇ
‚îÇ  - self.qa_chain (Feature 1)                    ‚îÇ
‚îÇ  - self.analysis_chain (Feature 2)              ‚îÇ
‚îÇ  - self.fix_chain (Feature 3)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ           ‚îÇ           ‚îÇ
       ‚ñº           ‚ñº           ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ  Q&A ‚îÇ   ‚îÇAnalyze‚îÇ   ‚îÇ Fix  ‚îÇ
   ‚îÇChain ‚îÇ   ‚îÇChain  ‚îÇ   ‚îÇChain ‚îÇ
   ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ          ‚îÇ           ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          VECTOR DATABASE (ChromaDB)             ‚îÇ
‚îÇ  912 documents ‚Üí 5,025 chunks                   ‚îÇ
‚îÇ  Each chunk has:                                ‚îÇ
‚îÇ  - Text content                                 ‚îÇ
‚îÇ  - 384-dimensional embedding vector             ‚îÇ
‚îÇ  - Metadata (source file, etc.)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
          Similarity Search
          (Cosine Distance)
                   ‚îÇ
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Top K Most Relevant Documents                ‚îÇ
‚îÇ  Example: Top 5 findings about "reentrancy"    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         LLM (Ollama gemma3:4b)                  ‚îÇ
‚îÇ  Input: Question + Retrieved Documents          ‚îÇ
‚îÇ  Output: Generated Answer                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         RESPONSE TO USER                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow Example: Q&A Feature

**User asks:** "What is a reentrancy attack?"

**Step 1: Embedding**
```python
question = "What is a reentrancy attack?"
question_vector = embedding_model.embed(question)
# Result: [0.23, -0.45, 0.78, ..., 0.12] (384 numbers)
```

**Step 2: Vector Search**
```python
# ChromaDB searches 5,025 chunks
# Calculates cosine similarity between question_vector and all chunk vectors
# Returns top 5 most similar chunks

similar_chunks = [
  "Finding #62123: Reentrancy vulnerability in withdrawal function...",
  "Finding #62445: Recursive call vulnerability allows attacker...",
  "Finding #63001: State changes after external call...",
  "Finding #62890: Missing reentrancy guard in transfer...",
  "Finding #63234: CEI pattern violation in withdraw..."
]
```

**Step 3: Prompt Construction**
```python
prompt = f"""
Use the following findings to answer the question:

{similar_chunks[0]}
{similar_chunks[1]}
{similar_chunks[2]}
{similar_chunks[3]}
{similar_chunks[4]}

Question: {question}

Answer:
"""
```

**Step 4: LLM Generation**
```python
llm_response = llm.predict(prompt)
# Result: "A reentrancy attack is a vulnerability where..."
```

**Step 5: Return to User**
```python
return {
    'answer': llm_response,
    'sources': similar_chunks
}
```

### Component Breakdown

#### 1. Vector Database (database.py)

**Purpose**: Store and retrieve vulnerability findings

**Key Functions:**

```python
def load_vulnerability_database():
    # Loads 912 JSON files from sample-smart-contract-dataset/
    # Splits each into ~5.5 chunks on average (5,025 total)
    # Creates embeddings using HuggingFace model
    # Stores in ChromaDB at ./chroma_db/
```

**Embedding Model:**
- Model: `sentence-transformers/all-MiniLM-L6-v2`
- Size: ~80MB
- Output: 384-dimensional vectors
- Speed: ~500 sentences/second
- Free and local (no API calls)

**Text Splitting:**
```python
chunk_size=1000 characters
chunk_overlap=200 characters

Example:
Original doc (2500 chars) ‚Üí
  Chunk 1: [0-1000]
  Chunk 2: [800-1800]  # 200 char overlap with chunk 1
  Chunk 3: [1600-2500] # 200 char overlap with chunk 2
```

Why overlap? Prevents important info from being split across chunks.

#### 2. LLM (Ollama gemma3:4b)

**What is Ollama?**
- Local LLM runtime (like Docker for AI models)
- Downloads and runs models on your computer
- Runs on localhost:11434
- No internet needed after download
- 100% free

**What is gemma3:4b?**
- Model by Google
- Size: 3.3GB
- Parameters: 4 billion
- Context window: 8192 tokens (~6000 words)
- Good balance of quality and speed

**Why local LLM?**
- ‚úÖ Free (no API costs)
- ‚úÖ Privacy (data stays on your computer)
- ‚úÖ Offline (works without internet)
- ‚ùå Slower than cloud APIs
- ‚ùå Lower quality than GPT-4 or Claude

#### 3. Chains (chains.py)

**What are Chains?**
Pre-built workflows that connect multiple LLM operations.

**Feature 1: Q&A Chain**
```python
RetrievalQA chain:
  1. Convert question to embedding
  2. Search vector DB
  3. Format prompt with retrieved docs
  4. Call LLM
  5. Return answer + sources
```

**Feature 2: Analysis Chain**
```python
Custom chain:
  1. Search for similar code patterns (k=10)
  2. Create analysis prompt with context
  3. LLM analyzes code
  4. Return analysis + relevant findings
```

**Feature 3: Fix Chain**
```python
Custom chain:
  1. Search for vulnerabilities (k=5)
  2. Search for fixes (k=5)
  3. Combine all findings
  4. LLM rewrites code
  5. Return fixed code + explanations
```

---

## Code Walkthrough

### File Structure

```
project_3/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # Entry point, CLI interface
‚îÇ   ‚îú‚îÄ‚îÄ database.py      # Vector database setup
‚îÇ   ‚îú‚îÄ‚îÄ chains.py        # LangChain chains (3 features)
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py      # Package marker
‚îú‚îÄ‚îÄ sample-smart-contract-dataset/  # 1000+ JSON files
‚îú‚îÄ‚îÄ chroma_db/           # Vector database storage
‚îú‚îÄ‚îÄ .env                 # Environment variables
‚îú‚îÄ‚îÄ .env.example         # Example env file
‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies
‚îî‚îÄ‚îÄ PROJECT_GUIDE.md     # This file
```

### main.py - Entry Point

**Purpose**: CLI interface and bot initialization

**Key Class:**
```python
class SmartContractSecurityBot:
    def __init__(self):
        # Load vector database (912 docs ‚Üí 5,025 chunks)
        self.vectorstore = load_vulnerability_database()

        # Initialize local LLM
        self.llm = Ollama(model="gemma3:4b", temperature=0)

        # Create 3 chains
        self.qa_chain = create_qa_chain(self.llm, self.vectorstore)
        self.analysis_chain = create_analysis_chain(self.llm, self.vectorstore)
        self.fix_chain = create_fix_chain(self.llm, self.vectorstore)
```

**Key Methods:**
```python
def answer_question(question):
    # Feature 1: Q&A
    # Returns: {'answer': str, 'sources': [docs]}

def analyze_code(code):
    # Feature 2: Code Analysis
    # Returns: {'analysis': str, 'relevant_findings': [docs]}

def fix_code(code):
    # Feature 3: Code Fixing
    # Returns: {'fixed_code': str, 'references': [docs]}
```

**CLI Flow:**
```python
while True:
    mode = input("Select mode (1/2/3) or 'quit': ")

    if mode == '1':
        # Q&A mode
        question = input("Your question: ")
        result = bot.answer_question(question)
        print(result['answer'])

    elif mode == '2':
        # Analysis mode
        code = read_multiline_input()
        result = bot.analyze_code(code)
        print(result['analysis'])

    elif mode == '3':
        # Fix mode
        code = read_multiline_input()
        result = bot.fix_code(code)
        print(result['fixed_code'])
```

### database.py - Vector Database

**Purpose**: Load JSON files, create embeddings, store in ChromaDB

**Key Function:**
```python
def load_vulnerability_database(
    data_dir="sample-smart-contract-dataset",
    persist_dir="./chroma_db"
):
    # Check if already created
    if os.path.exists(persist_dir):
        # Load existing database (fast)
        return Chroma(
            persist_directory=persist_dir,
            embedding_function=HuggingFaceEmbeddings(...)
        )

    # Create new database (slow, first-time only)

    # 1. Load JSON files
    loader = DirectoryLoader(
        data_dir,
        glob="**/*.json",  # Find all .json files recursively
        loader_cls=JSONLoader
    )
    documents = loader.load()  # 912 documents

    # 2. Split into chunks
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    splits = text_splitter.split_documents(documents)  # 5,025 chunks

    # 3. Create embeddings and store
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2"),
        persist_directory=persist_dir
    )

    return vectorstore
```

**What happens behind the scenes:**
```python
# For each chunk:
chunk_text = "Finding #62123: Reentrancy vulnerability in..."

# Create embedding (384 numbers)
embedding = embedding_model.embed(chunk_text)
# embedding = [0.23, -0.45, 0.78, ..., 0.12]

# Store in ChromaDB
chromadb.add(
    id="chunk_123",
    embedding=embedding,
    document=chunk_text,
    metadata={'source': 'finding_62123.json'}
)
```

### chains.py - LangChain Chains

**Feature 1: Q&A Chain**
```python
def create_qa_chain(llm, vectorstore):
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",  # Put all context in one prompt
        retriever=vectorstore.as_retriever(
            search_kwargs={"k": 5}  # Top 5 results
        ),
        return_source_documents=True,
        verbose=True  # Print what's happening
    )
```

**What "stuff" means:**
- Take all 5 retrieved documents
- Stuff them into a single prompt
- Send to LLM in one call

**Alternative chain types:**
- `map_reduce`: Analyze each doc separately, then combine
- `refine`: Iteratively refine answer with each doc
- `map_rerank`: Generate multiple answers, rank them

**Feature 2: Analysis Chain**
```python
def create_analysis_chain(llm, vectorstore):

    # Define prompt template
    analysis_template = """
    You are a smart contract security expert.

    Reference findings:
    {context}

    Code to analyze:
    {code}

    Provide detailed security analysis...
    """

    # Create custom chain
    def analyze_code(code):
        # 1. Search for similar code/vulnerabilities
        docs = vectorstore.similarity_search(code, k=10)
        context = "\n\n".join([doc.page_content for doc in docs])

        # 2. Run LLM analysis
        chain = LLMChain(llm=llm, prompt=prompt)
        result = chain.run(context=context, code=code)

        return {'analysis': result, 'relevant_findings': docs}

    return type('AnalysisChain', (), {'run': analyze_code})()
```

**Why custom chain?**
- More control over retrieval (k=10 instead of default 5)
- Custom prompt formatting
- Return both analysis and sources

**Feature 3: Fix Chain**
```python
def create_fix_chain(llm, vectorstore):

    fix_template = """
    Fix the vulnerabilities in this code:

    Vulnerability findings:
    {context}

    Code:
    {code}

    Provide:
    1. Fixed code
    2. Explanation of changes
    3. Security patterns applied
    """

    def fix_code(code):
        # 1. Search for vulnerabilities
        vuln_docs = vectorstore.similarity_search(code, k=5)

        # 2. Search for fixes
        fix_docs = vectorstore.similarity_search(
            "fix recommendation secure code",
            k=5
        )

        # 3. Combine context
        all_docs = vuln_docs + fix_docs
        context = "\n\n".join([doc.page_content for doc in all_docs])

        # 4. Generate fix
        chain = LLMChain(llm=llm, prompt=prompt)
        result = chain.run(context=context, code=code)

        return {'fixed_code': result, 'references': all_docs}

    return type('FixChain', (), {'run': fix_code})()
```

**Why two searches?**
- First search finds vulnerabilities in similar code
- Second search finds general fix recommendations
- Combining both gives LLM better context

---

## How It Works: Step by Step

### Complete Example: Q&A Feature

**User asks:** "What is a reentrancy attack?"

**Step 1: User Input**
```python
question = "What is a reentrancy attack?"
result = bot.answer_question(question)
```

**Step 2: Chain Execution**
```python
# Inside answer_question():
result = self.qa_chain(question)

# The RetrievalQA chain automatically does:
```

**Step 3: Embedding Creation**
```python
# Convert question to vector
question_vector = embedding_model.embed("What is a reentrancy attack?")
# Result: [0.234, -0.456, 0.789, ..., 0.123] (384 numbers)
```

**Step 4: Vector Search**
```python
# ChromaDB searches all 5,025 chunks
# Calculates cosine similarity with each chunk vector

similarities = []
for chunk in database:
    similarity = cosine_similarity(question_vector, chunk.vector)
    similarities.append((chunk, similarity))

# Sort by similarity, get top 5
top_5 = sorted(similarities, reverse=True)[:5]
```

**Actual results might be:**
```
1. Similarity: 0.89 - "Finding #62123: Reentrancy vulnerability..."
2. Similarity: 0.87 - "Finding #62445: Recursive call attack..."
3. Similarity: 0.85 - "Finding #63001: State changes after external call..."
4. Similarity: 0.83 - "Finding #62890: Missing reentrancy guard..."
5. Similarity: 0.81 - "Finding #63234: CEI pattern violation..."
```

**Step 5: Prompt Construction**
```python
prompt = f"""
Use the following pieces of context to answer the question at the end.

Context:
Finding #62123: Reentrancy vulnerability in withdrawal function allows
attacker to recursively call the function before state is updated...

Finding #62445: Recursive call attack exploits external calls made before
state changes. Recommendation: Follow Checks-Effects-Interactions pattern...

Finding #63001: State changes after external call create vulnerability
window. Impact: CRITICAL. Recommendation: Update state before external calls...

[... 2 more findings ...]

Question: What is a reentrancy attack?

Answer:
"""
```

**Step 6: LLM Generation**
```python
# Send prompt to Ollama gemma3:4b
response = llm.predict(prompt)

# LLM generates answer based on the 5 findings
response = """
A reentrancy attack is a critical vulnerability in smart contracts where
an attacker can recursively call a function before the contract's state
is updated. This typically occurs when:

1. The contract makes an external call (e.g., sending ETH)
2. Before updating its internal state (e.g., balance)
3. The attacker's contract calls back into the vulnerable function
4. Repeating this loop to drain funds

The classic example is TheDAO hack (2016) which led to $60M loss and
Ethereum hard fork.

Prevention:
- Follow Checks-Effects-Interactions pattern
- Update state before external calls
- Use ReentrancyGuard modifier
- Limit gas with .transfer() or .send()
"""
```

**Step 7: Return to User**
```python
return {
    'answer': response,
    'sources': top_5_findings
}
```

**Step 8: Display**
```python
print(f"Answer: {result['answer']}")
print(f"\nSources: {len(result['sources'])} findings used")
```

### Complete Example: Code Analysis Feature

**User pastes:**
```solidity
contract Vulnerable {
    mapping(address => uint) public balances;

    function withdraw(uint amount) public {
        require(balances[msg.sender] >= amount);
        msg.sender.call{value: amount}("");
        balances[msg.sender] -= amount;
    }
}
```

**Step 1: Vector Search**
```python
# Convert entire code to vector
code_vector = embedding_model.embed(code)

# Search for similar code patterns
similar_findings = vectorstore.similarity_search(code, k=10)
```

**Step 2: LLM Analysis**
```python
context = """
Finding #62123: Reentrancy in withdrawal - external call before state update
Finding #62445: Missing reentrancy guard in transfer function
Finding #63001: State modification after external call - CRITICAL
...
"""

prompt = f"""
Analyze this code for vulnerabilities:

{code}

Reference findings:
{context}

Provide detailed analysis...
"""

analysis = llm.predict(prompt)
```

**Step 3: LLM Output**
```
SECURITY ANALYSIS

1. REENTRANCY VULNERABILITY - CRITICAL
   Location: Line 6-7
   Issue: External call (msg.sender.call) before state update

   The function calls msg.sender.call{value: amount}("") at line 6,
   then updates balances[msg.sender] at line 7. This allows the attacker
   to re-enter withdraw() before their balance is updated.

   Similar to: Finding #62123, #63001

   Impact: Complete fund drainage

2. MISSING REENTRANCY GUARD - HIGH
   No ReentrancyGuard modifier protecting the function
   Similar to: Finding #62445

3. UNSAFE EXTERNAL CALL - MEDIUM
   Using .call() without checking return value

RECOMMENDATIONS:
1. Move state update before external call
2. Add ReentrancyGuard modifier
3. Use .transfer() instead of .call()
4. Check return values
```

### Complete Example: Code Fixing Feature

**Step 1: Dual Search**
```python
# Search 1: Find vulnerabilities in this code
vuln_findings = vectorstore.similarity_search(code, k=5)

# Search 2: Find general fix recommendations
fix_findings = vectorstore.similarity_search(
    "fix recommendation secure code best practices",
    k=5
)

all_context = vuln_findings + fix_findings  # 10 findings total
```

**Step 2: LLM Fixing**
```python
prompt = f"""
Fix this vulnerable code:

{code}

Vulnerability findings:
{vuln_context}

Fix recommendations:
{fix_context}

Provide fixed code and explanations...
"""

fixed = llm.predict(prompt)
```

**Step 3: LLM Output**
```
FIXED CODE:

```solidity
import "@openzeppelin/contracts/security/ReentrancyGuard.sol";

contract Secure is ReentrancyGuard {
    mapping(address => uint) public balances;

    function withdraw(uint amount) public nonReentrant {
        require(balances[msg.sender] >= amount, "Insufficient balance");

        // CEI Pattern: Update state BEFORE external call
        balances[msg.sender] -= amount;

        // Safe external call
        (bool success, ) = msg.sender.call{value: amount}("");
        require(success, "Transfer failed");
    }
}
```

CHANGES MADE:

1. Added ReentrancyGuard (Finding #62445)
   - Imported OpenZeppelin's ReentrancyGuard
   - Applied nonReentrant modifier

2. Checks-Effects-Interactions Pattern (Finding #62123, #63001)
   - Moved state update (effect) before external call (interaction)
   - Line 9: balances updated BEFORE line 12: external call

3. Return Value Checking (Finding #63567)
   - Check bool success from .call()
   - Revert if transfer fails

4. Error Messages (Finding #63789)
   - Added descriptive require messages

SECURITY PATTERNS APPLIED:
- Checks-Effects-Interactions (CEI)
- Reentrancy Guard
- Fail-Fast with require()
```

---

## Advanced Topics

### 1. How Embeddings Work (Mathematical Detail)

**Creating Embeddings:**

```python
sentence = "reentrancy attack"

# Neural network (transformer model) processes:
tokens = tokenize(sentence)  # ["reen", "##tran", "##cy", "attack"]

# Each token ‚Üí vector
token_vectors = [
    [0.1, 0.2, ..., 0.3],  # "reen"
    [0.4, 0.1, ..., 0.2],  # "##tran"
    [0.3, 0.5, ..., 0.4],  # "##cy"
    [0.2, 0.3, ..., 0.1]   # "attack"
]

# Pool token vectors (mean/max/cls)
sentence_vector = mean(token_vectors)
# Result: [0.25, 0.275, ..., 0.25]  (384 dimensions)
```

**Similarity Calculation:**

```python
# Cosine similarity
def cosine_similarity(vec_a, vec_b):
    dot_product = sum(a * b for a, b in zip(vec_a, vec_b))
    magnitude_a = sqrt(sum(a * a for a in vec_a))
    magnitude_b = sqrt(sum(b * b for b in vec_b))

    return dot_product / (magnitude_a * magnitude_b)

# Result: -1 to 1
# 1 = identical
# 0 = orthogonal (unrelated)
# -1 = opposite
```

**Example:**
```python
vec_reentrancy = [0.8, 0.2, 0.6, ...]
vec_recursive = [0.7, 0.3, 0.5, ...]
vec_documentation = [0.1, 0.9, 0.1, ...]

similarity(vec_reentrancy, vec_recursive) = 0.92  # Very similar
similarity(vec_reentrancy, vec_documentation) = 0.15  # Not similar
```

### 2. ChromaDB Internals

**Storage Structure:**
```
chroma_db/
‚îú‚îÄ‚îÄ chroma.sqlite3          # Metadata database
‚îú‚îÄ‚îÄ index/
‚îÇ   ‚îú‚îÄ‚îÄ id_to_uuid.pkl      # Document ID mapping
‚îÇ   ‚îî‚îÄ‚îÄ index.bin           # HNSW index for fast search
‚îî‚îÄ‚îÄ data/
    ‚îî‚îÄ‚îÄ embeddings.parquet  # Actual vector data
```

**HNSW Index (Hierarchical Navigable Small World):**
- Fast approximate nearest neighbor search
- O(log N) search time instead of O(N)
- Trade-off: 95-99% accuracy vs 100% accuracy
- Much faster for large datasets

**Without HNSW:**
```python
# Linear search: Check ALL 5,025 chunks
for chunk in all_chunks:
    similarity = cosine_similarity(query_vec, chunk.vec)
# Time: 5,025 calculations
```

**With HNSW:**
```python
# Graph-based search: Check ~50-100 chunks
start_node = entry_point
current_node = start_node
while not found:
    neighbors = graph.neighbors(current_node)
    current_node = closest_neighbor(neighbors, query_vec)
# Time: ~50-100 calculations (50x faster!)
```

### 3. LLM Temperature Parameter

```python
llm = Ollama(model="gemma3:4b", temperature=0)
```

**What is temperature?**
Controls randomness in LLM output.

**Temperature = 0:**
- Deterministic (same input ‚Üí same output)
- Always picks the highest probability token
- Best for: Q&A, code generation, factual tasks

**Temperature = 0.7:**
- Some randomness
- Occasionally picks lower probability tokens
- Best for: Creative writing, brainstorming

**Temperature = 1.5:**
- Very random
- Often picks unusual tokens
- Best for: Poetry, experimental outputs

**Example:**
```
Prompt: "A reentrancy attack is a"

Temperature = 0:
"vulnerability where an attacker can recursively call a function"
(same output every time)

Temperature = 1.0:
"security issue that allows recursive function invocation"
OR
"vulnerability enabling repeated contract calls"
OR
"critical bug in smart contract execution flow"
(different each time)
```

### 4. Chunk Size and Overlap Trade-offs

**Current settings:**
```python
chunk_size=1000
chunk_overlap=200
```

**Why 1000 characters?**
- Not too small: Preserves context
- Not too large: Fits in LLM context window
- ~150-250 words (readable amount)

**Why 200 overlap?**
- Prevents splitting important info
- Example:
  ```
  Chunk 1: "...the vulnerability is caused by"
  Chunk 2: "external calls before state updates..."
  ```
  With overlap: Both chunks have complete sentence!

**Trade-offs:**

**Larger chunks (2000):**
- ‚úÖ More context per chunk
- ‚úÖ Fewer chunks (faster search)
- ‚ùå Less granular retrieval
- ‚ùå Might exceed LLM context window

**Smaller chunks (500):**
- ‚úÖ More precise retrieval
- ‚úÖ Better for specific queries
- ‚ùå More chunks (slower search)
- ‚ùå Less context per chunk

**More overlap (400):**
- ‚úÖ Even less info splitting
- ‚ùå More duplicate data
- ‚ùå More storage needed

### 5. Retrieval Parameter k (Top K Results)

**Q&A uses k=5:**
```python
retriever=vectorstore.as_retriever(search_kwargs={"k": 5})
```

**Analysis uses k=10:**
```python
docs = vectorstore.similarity_search(code, k=10)
```

**Why different values?**

**k=5 for Q&A:**
- Simple questions need less context
- Avoids overwhelming LLM with too much info
- Faster response
- Less LLM tokens used

**k=10 for Analysis:**
- Code analysis needs more examples
- More findings = better pattern matching
- Worth the extra tokens for thorough analysis

**Trade-offs:**

**Smaller k (3):**
- ‚úÖ Faster
- ‚úÖ More focused
- ‚ùå Might miss relevant info
- ‚ùå Less comprehensive

**Larger k (20):**
- ‚úÖ More comprehensive
- ‚úÖ Less likely to miss info
- ‚ùå Slower
- ‚ùå Might include irrelevant findings
- ‚ùå Exceeds LLM context window
- ‚ùå LLM might get confused by too much info

### 6. Prompt Engineering Best Practices

**Good Prompt Structure:**
```python
prompt = """
[ROLE]
You are a smart contract security expert.

[CONTEXT]
Use these vulnerability findings:
{context}

[TASK]
Analyze this code for security issues:
{code}

[FORMAT]
Provide:
1. List of vulnerabilities
2. Severity levels
3. Recommendations

[CONSTRAINTS]
- Be specific about line numbers
- Reference similar findings
- Explain the impact
"""
```

**Why this works:**
1. **Role**: Sets LLM behavior
2. **Context**: Provides knowledge
3. **Task**: Clear instruction
4. **Format**: Structures output
5. **Constraints**: Ensures quality

**Bad Prompt:**
```python
prompt = f"Analyze this code: {code}"
```
Too vague, no context, unclear output format.

### 7. Cost Optimization Strategies

**Current setup (Free):**
- Ollama: Free
- HuggingFace Embeddings: Free
- ChromaDB: Free
- Total: $0/month

**If using paid APIs:**

**Reduce embedding costs:**
```python
# Cache embeddings - don't re-embed same text
@lru_cache(maxsize=1000)
def cached_embed(text):
    return embedding_model.embed(text)
```

**Reduce LLM costs:**
```python
# Use cheaper model
llm = ChatOpenAI(model="gpt-3.5-turbo")  # $0.001 vs $0.03 for GPT-4

# Reduce output tokens
prompt += "\nProvide a concise answer (max 200 words)."

# Cache common questions
@lru_cache(maxsize=100)
def cached_qa(question):
    return bot.answer_question(question)
```

**Batch processing:**
```python
# Instead of 10 individual calls
for code in codes:
    analyze(code)  # 10 API calls

# Batch them
all_codes = "\n---\n".join(codes)
analyze(all_codes)  # 1 API call
```

---

## Presenting to Your Teacher

### What to Explain

#### 1. Problem Statement
"Smart contracts handle billions of dollars, but security audits are expensive and time-consuming. I built an AI assistant that democratizes security knowledge by making 1000+ real audit findings instantly searchable and usable."

#### 2. Technology Choice: RAG vs Finetuning
"I chose RAG because:
- My data is knowledge (findings), not behavior patterns
- 1000 findings is perfect for RAG but too small for finetuning
- RAG is ~100x cheaper ($0.01 vs $100+)
- Easy to update with new findings
- More transparent - you can see which findings were used"

#### 3. Architecture Overview
"Three main components:
1. Vector Database (ChromaDB) - stores 5,025 chunks from 912 findings
2. LLM (Ollama gemma3:4b) - generates answers based on retrieved context
3. LangChain - coordinates retrieval + generation"

#### 4. How It Works
"When a user asks 'What is reentrancy?':
1. Convert question to vector (384 numbers)
2. Search 5,025 chunks for most similar vectors
3. Return top 5 findings about reentrancy
4. LLM reads findings and generates answer
5. User gets answer + sources used"

#### 5. Features
"Three core features:
1. Q&A - Answer security questions using dataset
2. Code Analysis - Identify vulnerabilities in user code
3. Code Fixing - Automatically fix vulnerabilities"

#### 6. Results
"Successfully answers questions using local dataset. For example, asked about reentrancy attacks, retrieved 5 relevant findings, generated accurate answer explaining the vulnerability, prevention methods, and real-world impact."

### Demo Script

**1. Setup (30 seconds)**
```bash
python src/main.py
```
*Show loading sequence*

**2. Feature 1: Q&A (2 minutes)**
```
Mode: 1
Question: What is a reentrancy attack?
```
*Show answer and explain:*
- "Bot retrieved 5 findings from dataset"
- "Generated answer based on real audit findings"
- "Notice it mentions specific patterns like CEI"

**3. Feature 2: Code Analysis (2 minutes)**
```
Mode: 2
[Paste vulnerable contract]
```
*Show analysis and explain:*
- "Bot identified reentrancy vulnerability"
- "Matched with similar findings in database"
- "Provided severity level and recommendations"

**4. Feature 3: Code Fixing (2 minutes)**
```
Mode: 3
[Paste same vulnerable contract]
```
*Show fixed code and explain:*
- "Bot retrieved both vulnerabilities AND fixes"
- "Applied security patterns from dataset"
- "Generated production-ready code"

### Questions Your Teacher Might Ask

**Q: Why not just search the JSON files with grep?**
A: "Grep only finds exact keyword matches. Vector search understands meaning. For example, a user asking about 'prevent recursive calls' will find findings about 'reentrancy' even though the words are different. This is called semantic search."

**Q: Why not use OpenAI API?**
A: "I started with Ollama (local) to avoid costs and protect privacy. The trade-off is slightly lower quality and speed, but it's 100% free and works offline. For production, I could easily swap to OpenAI by changing one line of code thanks to LangChain's abstraction."

**Q: How accurate is it?**
A: "As accurate as the dataset. RAG can only return information in the knowledge base. If a vulnerability isn't in the 912 findings, it won't be found. This is both a limitation and a feature - it won't hallucinate information not in the dataset."

**Q: What would you improve?**
A: "Three things:
1. Add more findings (currently 912, could expand to 10,000+)
2. Add confidence scores (show how certain the bot is)
3. Build web UI (currently CLI only)
4. Add conversation memory (currently stateless)"

**Q: How is this different from ChatGPT?**
A: "ChatGPT uses its training data (cutoff date). My bot uses YOUR data (always current). ChatGPT might hallucinate findings that don't exist. My bot only uses real audit findings from the dataset. It's like ChatGPT with a curated knowledge base."

### Key Takeaways for Teacher

1. **Understanding of AI/ML**: Demonstrates knowledge of LLMs, embeddings, vector databases, and RAG

2. **Practical Application**: Builds working application, not just theoretical knowledge

3. **Architecture Skills**: Designs scalable system with proper separation of concerns

4. **Domain Knowledge**: Applies AI to real-world problem (smart contract security)

5. **Cost Awareness**: Makes informed decisions about free vs paid tools

6. **Code Quality**: Clean, documented, modular code

---

## Troubleshooting

### Common Issues

**1. "ModuleNotFoundError: No module named 'langchain'"**
```bash
pip install -r requirements.txt
```

**2. "Ollama is not running"**
- Check: `ollama list`
- Start Ollama app
- Pull model: `ollama pull gemma3:4b`

**3. "Database loading is very slow (first time)"**
- Normal! Creating embeddings for 5,025 chunks takes time
- First run: ~5-10 minutes
- Subsequent runs: ~2 seconds (loads from disk)

**4. "Out of memory"**
- Reduce chunk size in database.py
- Use smaller model: `ollama pull gemma:2b`
- Close other applications

**5. "LLM responses are slow"**
- Normal for local models
- gemma3:4b generates ~10-20 tokens/second
- Consider using cloud API for speed (costs money)

---

## Next Steps

### For Learning
1. Experiment with different values of k (top-k retrieval)
2. Try different chunk sizes and overlaps
3. Modify prompts to change output format
4. Add conversation memory
5. Build web UI with Streamlit or Gradio

### For Production
1. Add user authentication
2. Deploy to cloud (AWS/GCP/Azure)
3. Add database of analyzed contracts
4. Implement rate limiting
5. Add telemetry and monitoring

### For Research
1. Compare RAG vs finetuning empirically
2. Evaluate different embedding models
3. Test different LLMs (Llama, Mistral, GPT-4)
4. Measure accuracy with test set
5. Benchmark against commercial tools

---

## Additional Resources

### Documentation
- LangChain: https://python.langchain.com/
- ChromaDB: https://docs.trychroma.com/
- Ollama: https://ollama.com/library
- HuggingFace: https://huggingface.co/models

### Learning
- RAG Explained: https://www.pinecone.io/learn/retrieval-augmented-generation/
- Vector Databases: https://www.pinecone.io/learn/vector-database/
- Embeddings: https://platform.openai.com/docs/guides/embeddings
- Prompt Engineering: https://www.promptingguide.ai/

### Smart Contract Security
- SWC Registry: https://swcregistry.io/
- Consensys Best Practices: https://consensys.github.io/smart-contract-best-practices/
- OpenZeppelin: https://docs.openzeppelin.com/contracts/

---

## Conclusion

You've built a sophisticated RAG system that:
- ‚úÖ Loads 912 vulnerability findings
- ‚úÖ Creates 5,025 searchable chunks
- ‚úÖ Provides semantic search with vector embeddings
- ‚úÖ Generates answers using local LLM
- ‚úÖ Implements 3 features (Q&A, Analysis, Fixing)
- ‚úÖ Runs 100% free and offline

**Key concepts mastered:**
- RAG (Retrieval-Augmented Generation)
- Vector embeddings and similarity search
- Vector databases (ChromaDB)
- LangChain framework
- Local LLMs (Ollama)
- Prompt engineering

**This demonstrates:**
- Practical AI/ML skills
- Software architecture knowledge
- Domain expertise (smart contracts)
- Cost-effective decision making

Good luck with your presentation! üöÄ
